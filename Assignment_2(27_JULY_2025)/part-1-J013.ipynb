{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:04:54.856837Z",
     "iopub.status.busy": "2025-09-06T14:04:54.856288Z",
     "iopub.status.idle": "2025-09-06T14:04:57.880157Z",
     "shell.execute_reply": "2025-09-06T14:04:57.879310Z",
     "shell.execute_reply.started": "2025-09-06T14:04:54.856811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q tqdm\n",
    "import os, re, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading, cleaning, and tokenizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:15:42.222888Z",
     "iopub.status.busy": "2025-09-06T14:15:42.222232Z",
     "iopub.status.idle": "2025-09-06T14:15:49.390162Z",
     "shell.execute_reply": "2025-09-06T14:15:49.389423Z",
     "shell.execute_reply.started": "2025-09-06T14:15:42.222862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")  \n",
    "df['label'] = (df['sentiment'] == 'positive').astype(int)\n",
    "df = df[['review', 'label']]\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<br\\s*/?>\", \" \", text)          \n",
    "    text = re.sub(r\"[^a-z0-9\\s']\", \" \", text)       \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df['text'] = df['review'].apply(clean_text)\n",
    "\n",
    "def tokenize(s): \n",
    "    return s.split()\n",
    "\n",
    "MAX_VOCAB = 20000\n",
    "counter = Counter()\n",
    "for t in df['text']:\n",
    "    counter.update(tokenize(t))\n",
    "most_common = counter.most_common(MAX_VOCAB-2)  \n",
    "itos = ['<PAD>', '<OOV>'] + [w for w,_ in most_common]\n",
    "stoi = {w:i for i,w in enumerate(itos)}\n",
    "vocab_size = len(itos)\n",
    "print(\"Vocab size:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert tokenized text to padded sequences and split dataset into train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:15:49.391670Z",
     "iopub.status.busy": "2025-09-06T14:15:49.391418Z",
     "iopub.status.idle": "2025-09-06T14:15:51.289443Z",
     "shell.execute_reply": "2025-09-06T14:15:51.288539Z",
     "shell.execute_reply.started": "2025-09-06T14:15:49.391651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 200  \n",
    "\n",
    "def text_to_sequence(text, stoi, max_len=MAX_LEN):\n",
    "    toks = tokenize(text)\n",
    "    seq = [stoi.get(t, 1) for t in toks]  \n",
    "    if len(seq) >= max_len:\n",
    "        return seq[:max_len]\n",
    "    else:\n",
    "        return seq + [0]*(max_len - len(seq))\n",
    "\n",
    "df['seq'] = df['text'].apply(lambda x: text_to_sequence(x, stoi, MAX_LEN))\n",
    "\n",
    "train_val, test = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\n",
    "train, valid = train_test_split(train_val, test_size=0.111111, stratify=train_val['label'], random_state=42)\n",
    "\n",
    "print(len(train), len(valid), len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pre-trained GloVe vectors and building the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:15:51.290792Z",
     "iopub.status.busy": "2025-09-06T14:15:51.290509Z",
     "iopub.status.idle": "2025-09-06T14:15:59.302364Z",
     "shell.execute_reply": "2025-09-06T14:15:59.301715Z",
     "shell.execute_reply.started": "2025-09-06T14:15:51.290767Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19248/20000 tokens in GloVe\n"
     ]
    }
   ],
   "source": [
    "GLOVE_PATH = \"/kaggle/input/glove6b100dtxt/glove.6B.100d.txt\"  # download from: https... (put in working dir)\n",
    "EMB_DIM = 100\n",
    "\n",
    "emb_index = {}\n",
    "with open(GLOVE_PATH, 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        parts = line.rstrip().split(' ')\n",
    "        word = parts[0]\n",
    "        vec = np.asarray(parts[1:], dtype='float32')\n",
    "        if vec.shape[0] == EMB_DIM:\n",
    "            emb_index[word] = vec\n",
    "\n",
    "embedding_matrix = np.random.normal(scale=0.6, size=(vocab_size, EMB_DIM)).astype(np.float32)\n",
    "embedding_matrix[0] = np.zeros(EMB_DIM, dtype=np.float32)\n",
    "\n",
    "found = 0\n",
    "for i, token in enumerate(itos):\n",
    "    if token in emb_index:\n",
    "        embedding_matrix[i] = emb_index[token]\n",
    "        found += 1\n",
    "print(f\"Found {found}/{vocab_size} tokens in GloVe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:15:59.303889Z",
     "iopub.status.busy": "2025-09-06T14:15:59.303676Z",
     "iopub.status.idle": "2025-09-06T14:15:59.326871Z",
     "shell.execute_reply": "2025-09-06T14:15:59.326206Z",
     "shell.execute_reply.started": "2025-09-06T14:15:59.303871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.seqs = df['seq'].tolist()\n",
    "        self.labels = df['label'].astype(np.int64).tolist()\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.seqs[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(IMDBDataset(train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(IMDBDataset(valid), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(IMDBDataset(test), batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN with GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 — Defining the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:15:59.328387Z",
     "iopub.status.busy": "2025-09-06T14:15:59.328166Z",
     "iopub.status.idle": "2025-09-06T14:15:59.361776Z",
     "shell.execute_reply": "2025-09-06T14:15:59.361067Z",
     "shell.execute_reply.started": "2025-09-06T14:15:59.328362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaRNN(\n",
      "  (embedding): Embedding(20000, 100, padding_idx=0)\n",
      "  (rnn): RNN(100, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, emb_dim=EMB_DIM, hidden_size=128, num_layers=1, bidirectional=False, freeze_emb=True):\n",
    "        super().__init__()\n",
    "        vocab_size = embedding_matrix.shape[0]\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix))\n",
    "        if freeze_emb:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        self.rnn = nn.RNN(input_size=emb_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        mult = 2 if bidirectional else 1\n",
    "        self.fc = nn.Linear(hidden_size*mult, 1)\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)                      \n",
    "        out, h_n = self.rnn(emb)                     \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = torch.cat([h_n[-2], h_n[-1]], dim=1)\n",
    "        else:\n",
    "            hidden = h_n[-1]\n",
    "        logits = self.fc(hidden).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = VanillaRNN(embedding_matrix, hidden_size=128, bidirectional=True, freeze_emb=True).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 — Training the Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:15:59.362641Z",
     "iopub.status.busy": "2025-09-06T14:15:59.362456Z",
     "iopub.status.idle": "2025-09-06T14:16:15.703688Z",
     "shell.execute_reply": "2025-09-06T14:16:15.702928Z",
     "shell.execute_reply.started": "2025-09-06T14:15:59.362626Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 0.6815 f1 0.5642 | Val loss 0.7092 f1 0.6679\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss 0.6652 f1 0.5907 | Val loss 0.6890 f1 0.6087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss 0.6837 f1 0.5605 | Val loss 0.6707 f1 0.4608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train loss 0.6788 f1 0.5703 | Val loss 0.6561 f1 0.6154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss 0.6715 f1 0.5882 | Val loss 0.6727 f1 0.6725\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "EPOCHS = 5\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    losses, preds_all, trues_all = [], [], []\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, y in tqdm(loader, leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            preds_all += (probs >= 0.5).astype(int).tolist()\n",
    "            trues_all += y.cpu().numpy().astype(int).tolist()\n",
    "    avg_loss = np.mean(losses)\n",
    "    f1 = f1_score(trues_all, preds_all)\n",
    "    acc = accuracy_score(trues_all, preds_all)\n",
    "    return avg_loss, f1, acc\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_f1, train_acc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_f1, val_acc = run_epoch(valid_loader, train=False)\n",
    "    print(f\"Epoch {epoch}: Train loss {train_loss:.4f} f1 {train_f1:.4f} | Val loss {val_loss:.4f} f1 {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:16:15.704804Z",
     "iopub.status.busy": "2025-09-06T14:16:15.704518Z",
     "iopub.status.idle": "2025-09-06T14:16:15.992056Z",
     "shell.execute_reply": "2025-09-06T14:16:15.991482Z",
     "shell.execute_reply.started": "2025-09-06T14:16:15.704779Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.6707 | Test Acc: 0.5890\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1, test_acc = run_epoch(test_loader, train=False)\n",
    "print(f\"Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining the LSTM and Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:17:30.665141Z",
     "iopub.status.busy": "2025-09-06T14:17:30.664849Z",
     "iopub.status.idle": "2025-09-06T14:18:21.910200Z",
     "shell.execute_reply": "2025-09-06T14:18:21.909582Z",
     "shell.execute_reply.started": "2025-09-06T14:17:30.665118Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 0.6802 f1 0.5516 | Val loss 0.6375 f1 0.6910\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss 0.4667 f1 0.7865 | Val loss 0.4049 f1 0.8370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss 0.3860 f1 0.8296 | Val loss 0.3810 f1 0.8303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train loss 0.3591 f1 0.8436 | Val loss 0.3533 f1 0.8419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss 0.3429 f1 0.8511 | Val loss 0.3554 f1 0.8332\n"
     ]
    }
   ],
   "source": [
    "class LSTMClassifier(VanillaRNN):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # override rnn with LSTM\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.embedding.embedding_dim,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(128 * 2, 1)  # 256 → 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (h_n, c_n) = self.rnn(embedded)\n",
    "\n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
    "        else:\n",
    "            hidden = h_n[-1]\n",
    "\n",
    "        logits = self.fc(hidden).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "EPOCHS = 5\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    losses, preds_all, trues_all = [], [], []\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, y in tqdm(loader, leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            preds_all += (probs >= 0.5).astype(int).tolist()\n",
    "            trues_all += y.cpu().numpy().astype(int).tolist()\n",
    "    avg_loss = np.mean(losses)\n",
    "    f1 = f1_score(trues_all, preds_all)\n",
    "    acc = accuracy_score(trues_all, preds_all)\n",
    "    return avg_loss, f1, acc\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_f1, train_acc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_f1, val_acc = run_epoch(valid_loader, train=False)\n",
    "    print(f\"Epoch {epoch}: Train loss {train_loss:.4f} f1 {train_f1:.4f} | Val loss {val_loss:.4f} f1 {val_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:18:50.149183Z",
     "iopub.status.busy": "2025-09-06T14:18:50.148508Z",
     "iopub.status.idle": "2025-09-06T14:18:50.761646Z",
     "shell.execute_reply": "2025-09-06T14:18:50.761129Z",
     "shell.execute_reply.started": "2025-09-06T14:18:50.149158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.8422 | Test Acc: 0.8468\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1, test_acc = run_epoch(test_loader, train=False)\n",
    "print(f\"Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with Learned Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:19:54.123095Z",
     "iopub.status.busy": "2025-09-06T14:19:54.122467Z",
     "iopub.status.idle": "2025-09-06T14:20:12.819791Z",
     "shell.execute_reply": "2025-09-06T14:20:12.819235Z",
     "shell.execute_reply.started": "2025-09-06T14:19:54.123071Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaRNN(\n",
      "  (embedding): Embedding(20000, 100, padding_idx=0)\n",
      "  (rnn): RNN(100, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 0.6642 f1 0.6071 | Val loss 0.6523 f1 0.7217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss 0.6779 f1 0.5664 | Val loss 0.6750 f1 0.6657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss 0.6744 f1 0.5740 | Val loss 0.6854 f1 0.2034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train loss 0.6115 f1 0.6679 | Val loss 0.6278 f1 0.5888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss 0.6351 f1 0.6243 | Val loss 0.6489 f1 0.6828\n"
     ]
    }
   ],
   "source": [
    "model = VanillaRNN(embedding_matrix, hidden_size=128, bidirectional=True, freeze_emb=False).to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "EPOCHS = 5\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    losses, preds_all, trues_all = [], [], []\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, y in tqdm(loader, leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            preds_all += (probs >= 0.5).astype(int).tolist()\n",
    "            trues_all += y.cpu().numpy().astype(int).tolist()\n",
    "    avg_loss = np.mean(losses)\n",
    "    f1 = f1_score(trues_all, preds_all)\n",
    "    acc = accuracy_score(trues_all, preds_all)\n",
    "    return avg_loss, f1, acc\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_f1, train_acc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_f1, val_acc = run_epoch(valid_loader, train=False)\n",
    "    print(f\"Epoch {epoch}: Train loss {train_loss:.4f} f1 {train_f1:.4f} | Val loss {val_loss:.4f} f1 {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:22:00.251302Z",
     "iopub.status.busy": "2025-09-06T14:22:00.250358Z",
     "iopub.status.idle": "2025-09-06T14:22:00.525366Z",
     "shell.execute_reply": "2025-09-06T14:22:00.524831Z",
     "shell.execute_reply.started": "2025-09-06T14:22:00.251267Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.6958 | Test Acc: 0.6454\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1, test_acc = run_epoch(test_loader, train=False)\n",
    "print(f\"Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Learned Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:22:02.058356Z",
     "iopub.status.busy": "2025-09-06T14:22:02.058029Z",
     "iopub.status.idle": "2025-09-06T14:22:55.254445Z",
     "shell.execute_reply": "2025-09-06T14:22:55.253821Z",
     "shell.execute_reply.started": "2025-09-06T14:22:02.058337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (embedding): Embedding(20000, 100, padding_idx=0)\n",
      "  (rnn): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 0.5991 f1 0.6501 | Val loss 0.3621 f1 0.8551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss 0.2967 f1 0.8795 | Val loss 0.2859 f1 0.8826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss 0.2091 f1 0.9204 | Val loss 0.2768 f1 0.8849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train loss 0.1482 f1 0.9496 | Val loss 0.3097 f1 0.8812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss 0.0989 f1 0.9690 | Val loss 0.3595 f1 0.8764\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(\n",
    "    embedding_matrix,\n",
    "    hidden_size=128,\n",
    "    bidirectional=True,\n",
    "    freeze_emb= False\n",
    ").to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "EPOCHS = 5\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    losses, preds_all, trues_all = [], [], []\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, y in tqdm(loader, leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            preds_all += (probs >= 0.5).astype(int).tolist()\n",
    "            trues_all += y.cpu().numpy().astype(int).tolist()\n",
    "    avg_loss = np.mean(losses)\n",
    "    f1 = f1_score(trues_all, preds_all)\n",
    "    acc = accuracy_score(trues_all, preds_all)\n",
    "    return avg_loss, f1, acc\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_f1, train_acc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_f1, val_acc = run_epoch(valid_loader, train=False)\n",
    "    print(f\"Epoch {epoch}: Train loss {train_loss:.4f} f1 {train_f1:.4f} | Val loss {val_loss:.4f} f1 {val_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T14:22:55.255701Z",
     "iopub.status.busy": "2025-09-06T14:22:55.255445Z",
     "iopub.status.idle": "2025-09-06T14:22:55.852860Z",
     "shell.execute_reply": "2025-09-06T14:22:55.852183Z",
     "shell.execute_reply.started": "2025-09-06T14:22:55.255673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.8792 | Test Acc: 0.8820\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1, test_acc = run_epoch(test_loader, train=False)\n",
    "print(f\"Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 715814,
     "sourceId": 1246668,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
